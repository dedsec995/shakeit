{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dedsec995\\shakeit\\env\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dedsec995\\shakeit\\env\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\dedsec995\\shakeit\\env\\lib\\site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dedsec995\\shakeit\\env\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dedsec995\\shakeit\\env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Live Ca[p]ture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Mediapipe Feed', frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "255\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "#Why??\n",
    "print(cv2.waitKey(10))\n",
    "print(0xFF)\n",
    "print(ord('q'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            # print(landmarks)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Landmark Pose List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "print(len(landmarks))\n",
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.RIGHT_ELBOW\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#The Diff RUNS\n",
    "print(mp_pose.PoseLandmark.RIGHT_ELBOW)\n",
    "print(mp_pose.PoseLandmark.RIGHT_ELBOW.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9453428387641907\n",
      "x: 0.5534713864326477\n",
      "y: 1.4376816749572754\n",
      "z: 0.12229599803686142\n",
      "visibility: 0.5365027785301208\n",
      "\n",
      "x: 0.5765460729598999\n",
      "y: 1.573784351348877\n",
      "z: -0.24044449627399445\n",
      "visibility: 0.4852105379104614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].visibility)\n",
    "print(landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW])\n",
    "print(landmarks[mp_pose.PoseLandmark.RIGHT_WRIST])\n",
    "\n",
    "r_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 265)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuple, np Multiplyer, Non normalize co-ordinate, Sreen Res, Why Not int\n",
    "tuple(np.multiply(r_elbow, [640, 480]).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Go Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            r_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y] \n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(\"I am right Elbow\"), \n",
    "                           tuple(np.multiply(r_elbow, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                            )\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From The Vdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vdo2.mp4')\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # re_frame = cv2.resize(frame, (608, 1080))\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            r_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y] \n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(\"RE\"), \n",
    "                           tuple(np.multiply(r_elbow, [608, 1080]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                            )\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vdo2.mp4')\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # re_frame = cv2.resize(frame, (608, 1080))\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            r_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            r_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            r_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            l_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            l_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            l_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "            r_angle = calculate_angle(r_shoulder,r_elbow, r_wrist)\n",
    "            l_angle = calculate_angle(l_shoulder,l_elbow, l_wrist)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(r_angle), \n",
    "                           tuple(np.multiply(r_elbow, [608, 1080]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                            )\n",
    "                                                 \n",
    "            cv2.putText(image, str(l_angle), \n",
    "                           tuple(np.multiply(l_elbow, [608, 1080]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                            )\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarkz = ['x1',\n",
    " 'y1',\n",
    " 'z1',\n",
    " 'v1',\n",
    " 'x2',\n",
    " 'y2',\n",
    " 'z2',\n",
    " 'v2',\n",
    " 'x3',\n",
    " 'y3',\n",
    " 'z3',\n",
    " 'v3',\n",
    " 'x4',\n",
    " 'y4',\n",
    " 'z4',\n",
    " 'v4',\n",
    " 'x5',\n",
    " 'y5',\n",
    " 'z5',\n",
    " 'v5',\n",
    " 'x6',\n",
    " 'y6',\n",
    " 'z6',\n",
    " 'v6',\n",
    " 'x7',\n",
    " 'y7',\n",
    " 'z7',\n",
    " 'v7',\n",
    " 'x8',\n",
    " 'y8',\n",
    " 'z8',\n",
    " 'v8',\n",
    " 'x9',\n",
    " 'y9',\n",
    " 'z9',\n",
    " 'v9',\n",
    " 'x10',\n",
    " 'y10',\n",
    " 'z10',\n",
    " 'v10',\n",
    " 'x11',\n",
    " 'y11',\n",
    " 'z11',\n",
    " 'v11',\n",
    " 'a11',\n",
    " 'x12',\n",
    " 'y12',\n",
    " 'z12',\n",
    " 'v12',\n",
    " 'a12',\n",
    " 'x13',\n",
    " 'y13',\n",
    " 'z13',\n",
    " 'a13',\n",
    " 'v13',\n",
    " 'x14',\n",
    " 'y14',\n",
    " 'z14',\n",
    " 'v14',\n",
    " 'a14',\n",
    " 'x15',\n",
    " 'y15',\n",
    " 'z15',\n",
    " 'v15',\n",
    " 'x16',\n",
    " 'y16',\n",
    " 'z16',\n",
    " 'v16',\n",
    " 'a16',\n",
    " 'x17',\n",
    " 'y17',\n",
    " 'z17',\n",
    " 'v17',\n",
    " 'a17',\n",
    " 'x18',\n",
    " 'y18',\n",
    " 'z18',\n",
    " 'v18',\n",
    " 'x19',\n",
    " 'y19',\n",
    " 'z19',\n",
    " 'v19',\n",
    " 'x20',\n",
    " 'y20',\n",
    " 'z20',\n",
    " 'v20',\n",
    " 'x21',\n",
    " 'y21',\n",
    " 'z21',\n",
    " 'v21',\n",
    " 'x22',\n",
    " 'y22',\n",
    " 'z22',\n",
    " 'v22',\n",
    " 'x23',\n",
    " 'y23',\n",
    " 'z23',\n",
    " 'v23',\n",
    " 'a23',\n",
    " 'x24',\n",
    " 'y24',\n",
    " 'z24',\n",
    " 'v24',\n",
    " 'a24',\n",
    " 'x25',\n",
    " 'y25',\n",
    " 'z25',\n",
    " 'v25',\n",
    " 'a25',\n",
    " 'x26',\n",
    " 'y26',\n",
    " 'z26',\n",
    " 'v26',\n",
    " 'a26',\n",
    " 'x27',\n",
    " 'y27',\n",
    " 'z27',\n",
    " 'a27',\n",
    " 'v27',\n",
    " 'x28',\n",
    " 'y28',\n",
    " 'z28',\n",
    " 'v28',\n",
    " 'a28',\n",
    " 'x29',\n",
    " 'y29',\n",
    " 'z29',\n",
    " 'v29',\n",
    " 'x30',\n",
    " 'y30',\n",
    " 'z30',\n",
    " 'v30',\n",
    " 'x31',\n",
    " 'y31',\n",
    " 'z31',\n",
    " 'v31',\n",
    " 'x32',\n",
    " 'y32',\n",
    " 'z32',\n",
    " 'v32',\n",
    " 'x33',\n",
    " 'y33',\n",
    " 'z33',\n",
    " 'v33',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "144 columns passed, passed data had 132 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dedsec995\\shakeit\\env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:969\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    970\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    971\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dedsec995\\shakeit\\env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:1017\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_mi_list \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(columns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(content):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m     \u001b[39m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m-> 1017\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m   1018\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(columns)\u001b[39m}\u001b[39;00m\u001b[39m columns passed, passed data had \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(content)\u001b[39m}\u001b[39;00m\u001b[39m columns\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1021\u001b[0m \u001b[39melif\u001b[39;00m is_mi_list:\n\u001b[0;32m   1022\u001b[0m \n\u001b[0;32m   1023\u001b[0m     \u001b[39m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 144 columns passed, passed data had 132 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m row \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[res\u001b[39m.\u001b[39mx, res\u001b[39m.\u001b[39my, res\u001b[39m.\u001b[39mz, res\u001b[39m.\u001b[39mvisibility] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks\u001b[39m.\u001b[39mlandmark])\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m----> 2\u001b[0m X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame([row], columns \u001b[39m=\u001b[39;49m landmarkz) \n",
      "File \u001b[1;32mc:\\Users\\dedsec995\\shakeit\\env\\lib\\site-packages\\pandas\\core\\frame.py:746\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    745\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 746\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    747\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    748\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    749\u001b[0m         data,\n\u001b[0;32m    750\u001b[0m         columns,\n\u001b[0;32m    751\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    752\u001b[0m         dtype,\n\u001b[0;32m    753\u001b[0m     )\n\u001b[0;32m    754\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    755\u001b[0m         arrays,\n\u001b[0;32m    756\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    759\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    760\u001b[0m     )\n\u001b[0;32m    761\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dedsec995\\shakeit\\env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[1;32m--> 510\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    511\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    513\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dedsec995\\shakeit\\env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:875\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    872\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[0;32m    873\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 875\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[0;32m    876\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32mc:\\Users\\dedsec995\\shakeit\\env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:972\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    969\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    970\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    971\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 972\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contents) \u001b[39mand\u001b[39;00m contents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[0;32m    975\u001b[0m     contents \u001b[39m=\u001b[39m _convert_object_array(contents, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 144 columns passed, passed data had 132 columns"
     ]
    }
   ],
   "source": [
    "row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "X = pd.DataFrame([row], columns = landmarkz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        y1        z1        v1        x2        y2        z2  \\\n",
      "0  0.347583  0.429824 -0.211057  0.991145  0.354123  0.423713 -0.189131   \n",
      "\n",
      "         v2        x3        y3  ...       z31       v31       x32       y32  \\\n",
      "0  0.991369  0.357721  0.423695  ...  0.397926  0.663048  0.353486  0.682528   \n",
      "\n",
      "        z32      v32      x33       y33       z33       v33  \n",
      "0  0.089743  0.79271  0.32477  0.604578  0.401467  0.780271  \n",
      "\n",
      "[1 rows x 132 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7781b7c81ed8d58a47531ac6c390c67b57d7aa27bfd2fbc3c09bb819171cc821"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
